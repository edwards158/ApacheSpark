{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest Cover Type Dataset\n",
    "\n",
    "Playing around with a Kaggle dataset.  Using queries, SQL, Transformers and ML methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree types found in Roosevelt National Forest in Colorado\n",
    "\n",
    "Kaggle dataset downloaded from:\n",
    "- kaggle.com/uciml/forest-cover-type-dataset\n",
    "\n",
    "Try using various transformers and machine learning models on a Kaggle dataset\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Given is the attribute name, attribute type, the measurement unit and a brief description. The forest cover type is the classification problem. The order of this listing corresponds to the order of numerals along the rows of the database.\n",
    "\n",
    "Name / Data Type / Measurement / Description\n",
    "\n",
    "- Elevation / quantitative /meters / Elevation in meters\n",
    "- Aspect / quantitative / azimuth / Aspect in degrees azimuth\n",
    "- Slope / quantitative / degrees / Slope in degrees\n",
    "- Horizontal_Distance_To_Hydrology / quantitative / meters / Horz Dist to nearest surface water features\n",
    "- Vertical_Distance_To_Hydrology / quantitative / meters / Vert Dist to nearest surface water features\n",
    "- Horizontal_Distance_To_Roadways / quantitative / meters / Horz Dist to nearest roadway\n",
    "- Hillshade_9am / quantitative / 0 to 255 index / Hillshade index at 9am, summer solstice\n",
    "- Hillshade_Noon / quantitative / 0 to 255 index / Hillshade index at noon, summer soltice\n",
    "- Hillshade_3pm / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solstice\n",
    "- Horizontal_Distance_To_Fire_Points / quantitative / meters / Horz Dist to nearest wildfire ignition points\n",
    "- Wilderness_Area (4 binary columns) / qualitative / 0 (absence) or 1 (presence) / Wilderness area designation\n",
    "- Soil_Type (40 binary columns) / qualitative / 0 (absence) or 1 (presence) / Soil Type designation\n",
    "- Cover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/rich/spark/spark-2.4.3-bin-hadoop2.7')\n",
    "import pandas as pd\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.ml.feature as feat\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local[*]').appName('Forest').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV file\n",
    "forest = spark.read.csv('./data/covtype.csv',sep=',',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contain 581012 records.\n"
     ]
    }
   ],
   "source": [
    "print(\"The data contain %d records.\" % forest.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Elevation: integer (nullable = true)\n",
      " |-- Aspect: integer (nullable = true)\n",
      " |-- Slope: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Hydrology: integer (nullable = true)\n",
      " |-- Vertical_Distance_To_Hydrology: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Roadways: integer (nullable = true)\n",
      " |-- Hillshade_9am: integer (nullable = true)\n",
      " |-- Hillshade_Noon: integer (nullable = true)\n",
      " |-- Hillshade_3pm: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Fire_Points: integer (nullable = true)\n",
      " |-- Wilderness_Area_Rawah: integer (nullable = true)\n",
      " |-- Wilderness_Area_Neota: integer (nullable = true)\n",
      " |-- Wilderness_Area_Comanche: integer (nullable = true)\n",
      " |-- Wilderness_Area_CacheLaPoudre: integer (nullable = true)\n",
      " |-- Soil_type_2702: integer (nullable = true)\n",
      " |-- Soil_type_2703: integer (nullable = true)\n",
      " |-- Soil_type_2704: integer (nullable = true)\n",
      " |-- Soil_type_2705: integer (nullable = true)\n",
      " |-- Soil_type_2706: integer (nullable = true)\n",
      " |-- Soil_type_2717: integer (nullable = true)\n",
      " |-- Soil_type_3501: integer (nullable = true)\n",
      " |-- Soil_type_3502: integer (nullable = true)\n",
      " |-- Soil_type_4201: integer (nullable = true)\n",
      " |-- Soil_type_4703: integer (nullable = true)\n",
      " |-- Soil_type_4704: integer (nullable = true)\n",
      " |-- Soil_type_4744: integer (nullable = true)\n",
      " |-- Soil_type_4758: integer (nullable = true)\n",
      " |-- Soil_type_5101: integer (nullable = true)\n",
      " |-- Soil_type_5151: integer (nullable = true)\n",
      " |-- Soil_type_6101: integer (nullable = true)\n",
      " |-- Soil_type_6102: integer (nullable = true)\n",
      " |-- Soil_type_6731: integer (nullable = true)\n",
      " |-- Soil_type_7101: integer (nullable = true)\n",
      " |-- Soil_type_7102: integer (nullable = true)\n",
      " |-- Soil_type_7103: integer (nullable = true)\n",
      " |-- Soil_type_7201: integer (nullable = true)\n",
      " |-- Soil_type_7202: integer (nullable = true)\n",
      " |-- Soil_type_7700: integer (nullable = true)\n",
      " |-- Soil_type_7701: integer (nullable = true)\n",
      " |-- Soil_type_7702: integer (nullable = true)\n",
      " |-- Soil_type_7709: integer (nullable = true)\n",
      " |-- Soil_type_7710: integer (nullable = true)\n",
      " |-- Soil_type_7745: integer (nullable = true)\n",
      " |-- Soil_type_7746: integer (nullable = true)\n",
      " |-- Soil_type_7755: integer (nullable = true)\n",
      " |-- Soil_type_7756: integer (nullable = true)\n",
      " |-- Soil_type_7757: integer (nullable = true)\n",
      " |-- Soil_type_7790: integer (nullable = true)\n",
      " |-- Soil_type_8703: integer (nullable = true)\n",
      " |-- Soil_type_8707: integer (nullable = true)\n",
      " |-- Soil_type_8708: integer (nullable = true)\n",
      " |-- Soil_type_8771: integer (nullable = true)\n",
      " |-- Soil_type_8772: integer (nullable = true)\n",
      " |-- Soil_type_8776: integer (nullable = true)\n",
      " |-- CoverType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|Horizontal_Distance_To_Hydrology|\n",
      "+--------------------------------+\n",
      "|                             258|\n",
      "|                             212|\n",
      "|                             268|\n",
      "|                             242|\n",
      "|                             153|\n",
      "|                             300|\n",
      "|                             270|\n",
      "|                             234|\n",
      "|                             240|\n",
      "|                             247|\n",
      "+--------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest.select('Horizontal_Distance_To_Hydrology').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucketizing\n",
    "\n",
    "Putting the *Horizontal_Distance_To_Hydrology* into discrete buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "|min| max|\n",
      "+---+----+\n",
      "|  0|1397|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#getting min and max using sql\n",
    "forest.createOrReplaceTempView(\"Hydro\")\n",
    "query = '''select min(Horizontal_Distance_To_Hydrology) as min, \n",
    "           max(Horizontal_Distance_To_Hydrology) as max from Hydro'''\n",
    "forest_hydro = spark.sql(query)\n",
    "forest_hydro.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(MAX=1397)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting min and max using dot notation\n",
    "row = forest.agg({\"Horizontal_Distance_To_Hydrology\":\"max\"}).collect()[0][0]\n",
    "print(row)\n",
    "\n",
    "#another way\n",
    "forest.select(F.max(F.col(\"Horizontal_Distance_To_Hydrology\")).alias(\"MAX\")).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1397)\n"
     ]
    }
   ],
   "source": [
    "#a faster way to do it\n",
    "#want 10 buckets\n",
    "buckets_no = 10\n",
    "\n",
    "dist_min_max = (\n",
    "    forest.agg(\n",
    "          F.min('Horizontal_Distance_To_Hydrology')\n",
    "            .alias('min')\n",
    "        , F.max('Horizontal_Distance_To_Hydrology')\n",
    "            .alias('max')\n",
    "    )\n",
    "    .rdd\n",
    "    .map(lambda row: (row.min, row.max))\n",
    "    .collect()[0]\n",
    ")\n",
    "print(dist_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 127.0, 254.0, 381.0, 508.0, 635.0, 762.0, 889.0, 1016.0, 1143.0, 1270.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the range of values\n",
    "rng = dist_min_max[1] - dist_min_max[0]\n",
    "\n",
    "#make a list of thresholds, use numpy arange min, max,step size\n",
    "splits = list(np.arange(dist_min_max[0],dist_min_max[1],rng/(buckets_no+1)))\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+------------------------------------+\n",
      "|Horizontal_Distance_To_Hydrology|Horizontal_Distance_To_Hydrology_Bkt|\n",
      "+--------------------------------+------------------------------------+\n",
      "|                             258|                                 2.0|\n",
      "|                             212|                                 1.0|\n",
      "|                             268|                                 2.0|\n",
      "|                             242|                                 1.0|\n",
      "|                             153|                                 1.0|\n",
      "|                             300|                                 2.0|\n",
      "|                             270|                                 2.0|\n",
      "|                             234|                                 1.0|\n",
      "|                             240|                                 1.0|\n",
      "|                             247|                                 1.0|\n",
      "+--------------------------------+------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make and apply the bucketizer\n",
    "bucketizer = feat.Bucketizer(\n",
    "        splits = splits,\n",
    "        inputCol = 'Horizontal_Distance_To_Hydrology',\n",
    "        outputCol = 'Horizontal_Distance_To_Hydrology_Bkt'\n",
    ")\n",
    "#use object to transform the df\n",
    "bucketizer.transform(forest).select(\n",
    "                                    'Horizontal_Distance_To_Hydrology',\n",
    "                                    'Horizontal_Distance_To_Hydrology_Bkt'\n",
    "                                    ).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing\n",
    "VectorAssembler collates multiple features into a single column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feat'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorAssembler = feat.VectorAssembler(inputCols=forest.columns,outputCol='feat')\n",
    "vectorAssembler.getOutputCol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(feat=SparseVector(55, {0: 2596.0, 1: 51.0, 2: 3.0, 3: 258.0, 5: 510.0, 6: 221.0, 7: 232.0, 8: 148.0, 9: 6279.0, 10: 1.0, 42: 1.0, 54: 5.0}), pca_feat=DenseVector([-3887.7711, 4996.8103, 2323.0932, 1014.5873, -135.1702]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply pca to all the features\n",
    "pca = feat.PCA(k=5,inputCol=vectorAssembler.getOutputCol(),outputCol='pca_feat')\n",
    "\n",
    "(\n",
    "pca.fit(vectorAssembler.transform(forest))\n",
    "        .transform(vectorAssembler.transform(forest))\n",
    "        .select('feat','pca_feat').take(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produced the top 5 pca components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimators\n",
    "Try classification and regression techniques using two models from ML library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.classification as cl\n",
    "\n",
    "#get just the features as vectorassembler\n",
    "vectorAssembler = feat.VectorAssembler(inputCols=forest.columns[:-1],outputCol='features')\n",
    "\n",
    "#transform the dataset, check  and cast whether target equal to 1\n",
    "forest_data = (\n",
    "        vectorAssembler\n",
    "        .transform(forest)\n",
    "        .withColumn('label',(F.col('CoverType')==1).cast('integer'))\n",
    "    .select('label','features')\n",
    "\n",
    ")\n",
    "#use log reg model\n",
    "log_obj = cl.LogisticRegression()\n",
    "log_model = log_obj.fit(forest_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0071, -0.0004, -0.0155, -0.0014, -0.0015, -0.0001, -0.0019, -0.0251, 0.0065, 0.0, -6.0389, -7.0751, -6.6708, -16.7513, -5.0649, -11.4737, -13.9752, -5.4082, -4.5281, -6.4561, -12.6817, -4.6724, -3.0293, -4.2446, -4.9244, -5.4026, -4.9246, -8.1625, -3.7149, -4.3748, -4.6184, -6.8022, -4.0672, -3.9113, 0.5552, -3.6307, -3.9406, -4.1827, -5.597, -4.967, -3.8844, -4.9093, -4.9629, -5.118, -4.2124, -4.6844, -4.2862, -6.3924, -6.3938, -7.2371, -16.6593, -5.795, -5.8279, -6.3668])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(54,[0,1,2,3,5,6,...|\n",
      "|    0|(54,[0,1,2,3,4,5,...|\n",
      "|    0|(54,[0,1,2,3,4,5,...|\n",
      "|    0|(54,[0,1,2,3,4,5,...|\n",
      "|    0|(54,[0,1,2,3,4,5,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using regression techinques - try to predict elevation\n",
    "import pyspark.ml.regression as rg\n",
    "\n",
    "#forest.select('Elevation').show(5)\n",
    "\n",
    "assembler = feat.VectorAssembler(inputCols = forest.columns[1:],outputCol='features')\n",
    "\n",
    "#cast to float as regression problem\n",
    "elevation_data = (\n",
    "    assembler\n",
    "    .transform(forest)\n",
    "    .withColumn(\n",
    "        'label'\n",
    "        , F.col('Elevation').cast('float'))\n",
    "    .select('label', 'features')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------------------------------------------------------------------------+\n",
      "|label |features                                                                                             |\n",
      "+------+-----------------------------------------------------------------------------------------------------+\n",
      "|2596.0|(54,[0,1,2,4,5,6,7,8,9,41,53],[51.0,3.0,258.0,510.0,221.0,232.0,148.0,6279.0,1.0,1.0,5.0])           |\n",
      "|2590.0|(54,[0,1,2,3,4,5,6,7,8,9,41,53],[56.0,2.0,212.0,-6.0,390.0,220.0,235.0,151.0,6225.0,1.0,1.0,5.0])    |\n",
      "|2804.0|(54,[0,1,2,3,4,5,6,7,8,9,24,53],[139.0,9.0,268.0,65.0,3180.0,234.0,238.0,135.0,6121.0,1.0,1.0,2.0])  |\n",
      "|2785.0|(54,[0,1,2,3,4,5,6,7,8,9,42,53],[155.0,18.0,242.0,118.0,3090.0,238.0,238.0,122.0,6211.0,1.0,1.0,2.0])|\n",
      "|2595.0|(54,[0,1,2,3,4,5,6,7,8,9,41,53],[45.0,2.0,153.0,-1.0,391.0,220.0,234.0,150.0,6172.0,1.0,1.0,5.0])    |\n",
      "+------+-----------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "elevation_data.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0309, 0.6522, 0.1911, 0.1424, 0.0342, 0.7402, 1.053, -0.0017, -0.0041, 2.7163, 189.0362, 27.8238, -265.8505, -407.4379, -346.0612, -364.3841, -302.6788, -400.5852, -212.9918, -126.1329, -117.7423, -312.0478, -248.7118, -221.4788, -155.1459, -84.5129, -398.0433, -387.8102, -179.4485, -261.3875, -337.7875, 48.0629, -94.7813, 149.8043, 135.144, 80.0901, 64.3659, 124.0233, -115.0126, 119.1285, -181.7498, 10.8056, -42.7849, 65.5441, 102.2562, 36.9865, -48.1163, 379.2091, 256.0169, 497.1714, 313.0607, 337.172, 397.0758, -14.4551])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_obj = rg.LinearRegression(\n",
    "    maxIter=10\n",
    "    , regParam=0.01\n",
    "    , elasticNetParam=1.00)\n",
    "lr_model = lr_obj.fit(elevation_data)\n",
    "\n",
    "lr_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7860412464754158 129.50871925702575 103.34079732698777\n"
     ]
    }
   ],
   "source": [
    "summary = lr_model.summary\n",
    "\n",
    "print(\n",
    "    summary.r2\n",
    "    , summary.rootMeanSquaredError\n",
    "    , summary.meanAbsoluteError\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 of 0.786 means we have modelled well using LR on this feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "Chain together Transformers and Estimators to form a sequential workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|Elevation|        prediction|\n",
      "+---------+------------------+\n",
      "|     2596|2840.7801831411316|\n",
      "|     2590|2828.7464246669683|\n",
      "|     2804| 2842.761272955131|\n",
      "|     2785| 2966.057500325109|\n",
      "|     2595|2817.1687155114637|\n",
      "|     2579|2892.6436548111983|\n",
      "|     2606| 2844.248065926093|\n",
      "|     2605|2838.8097383254494|\n",
      "|     2617|2845.6749236394053|\n",
      "|     2612|2841.6531550057234|\n",
      "+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "assembler = feat.VectorAssembler(\n",
    "    inputCols=forest.columns[1:]\n",
    "    , outputCol='features')\n",
    "\n",
    "lr_obj = rg.LinearRegression(\n",
    "    labelCol='Elevation'\n",
    "    , maxIter=10\n",
    "    , regParam=0.01\n",
    ")\n",
    "\n",
    "#create the pipeline and use on dataset\n",
    "pip = Pipeline(stages=[assembler, lr_obj])\n",
    "\n",
    "(\n",
    "    pip\n",
    "    .fit(forest)\n",
    "    .transform(forest)\n",
    "    .select('Elevation', 'prediction')\n",
    "    .show(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#what is distribution of elevation?\n",
    "transformed_df = forest.select('Elevation')\n",
    "transformed_df.toPandas().hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost a gaussian dist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "use chi square to select top 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            selected|\n",
      "+--------------------+\n",
      "|(10,[0,1,2,3,5,6,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "|(10,[0,1,2,3,4,5,...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = feat.VectorAssembler(\n",
    "    inputCols=forest.columns[0:-1]\n",
    "    , outputCol='features'\n",
    ")\n",
    "\n",
    "selector = feat.ChiSqSelector(\n",
    "    labelCol='CoverType'\n",
    "    , numTopFeatures=10\n",
    "    , outputCol='selected')\n",
    "\n",
    "pipeline_sel = Pipeline(stages=[assembler, selector])\n",
    "\n",
    "(\n",
    "    pipeline_sel\n",
    "    .fit(forest)\n",
    "    .transform(forest)\n",
    "    .select(selector.getOutputCol())\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression problems select best features by checking the correlations between each and very feature and the target and slect those that are most hghly correlated with the target but exhibit little to no correlation with other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting forest coverage types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "forest_train, forest_test = (forest.randomSplit([0.75,0.25],seed=27))\n",
    "\n",
    "#vectorize the features\n",
    "assembler = feat.VectorAssembler(inputCols=forest.columns[:-1],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435321\n",
      "145691\n"
     ]
    }
   ],
   "source": [
    "print(forest_train.count())\n",
    "print(forest_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 10 features\n",
    "selector = feat.ChiSqSelector(\n",
    "    labelCol='CoverType'\n",
    "    , numTopFeatures=10\n",
    "    , outputCol='selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply logistic regression\n",
    "logReg_obj = cl.LogisticRegression(\n",
    "    labelCol='CoverType'\n",
    "    , featuresCol=selector.getOutputCol()\n",
    "    , regParam=0.01\n",
    "    , elasticNetParam=1.0\n",
    "    , family='multinomial'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make and fit our piepline\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        vectorAssembler\n",
    "        , selector\n",
    "        , logReg_obj\n",
    "    ])\n",
    "\n",
    "pModel = pipeline.fit(forest_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6005001943648852, 0.5819004790151103, 0.6335326135451057)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.ml.evaluation as ev\n",
    "\n",
    "#get the predictions for the unseen data\n",
    "results_logReg = (\n",
    "    pModel\n",
    "    .transform(forest_test)\n",
    "    .select('CoverType', 'probability', 'prediction')\n",
    ")\n",
    "\n",
    "\n",
    "#calculate the performance on the model.  \n",
    "evaluator = ev.MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction'  #name of the column that contains the predicted class for observatuions\n",
    "    , labelCol='CoverType')  #true label\n",
    "\n",
    "(\n",
    "    #return the results default is F1 score \n",
    "    evaluator.evaluate(results_logReg)\n",
    "    , evaluator.evaluate(\n",
    "        results_logReg\n",
    "        , {evaluator.metricName: 'weightedPrecision'}\n",
    "    ) \n",
    "    , evaluator.evaluate(\n",
    "        results_logReg\n",
    "        , {evaluator.metricName: 'accuracy'}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accruacy of around sixty percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the hyperparameters\n",
    "\n",
    "Try a simple grid search using the regularization param.  Only select 5 features for speed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.tuning as tune\n",
    "\n",
    "#assembler and selector same as above\n",
    "\n",
    "selector = feat.ChiSqSelector(\n",
    "    labelCol='CoverType'\n",
    "    , numTopFeatures=5\n",
    "    , outputCol='selected')\n",
    "\n",
    "logReg_obj = cl.LogisticRegression(\n",
    "    labelCol='CoverType'\n",
    "    , featuresCol=selector.getOutputCol()\n",
    "    , family='multinomial'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the grid regulariztion techniques\n",
    "logReg_grid = (\n",
    "    tune.ParamGridBuilder()\n",
    "    .addGrid(logReg_obj.regParam\n",
    "            , [0.05, 0.1]\n",
    "        )\n",
    "    .build()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_ev = ev.MulticlassClassificationEvaluator(\n",
    "    predictionCol='prediction'\n",
    "    , labelCol='CoverType')\n",
    "\n",
    "#cv by default on 3 folds\n",
    "cross_v = tune.CrossValidator(\n",
    "    estimator=logReg_obj\n",
    "    , estimatorParamMaps=logReg_grid\n",
    "    , evaluator=logReg_ev\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[vectorAssembler, selector])\n",
    "data_trans = pipeline.fit(forest_train)\n",
    "\n",
    "logReg_modelTest = cross_v.fit(\n",
    "    data_trans.transform(forest_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5989028399279137\n",
      "0.6523464043763857\n",
      "0.6523464043763857\n"
     ]
    }
   ],
   "source": [
    "#evaluate on test dataset\n",
    "data_trans_test = data_trans.transform(forest_test)\n",
    "results = logReg_modelTest.transform(data_trans_test)\n",
    "\n",
    "print(logReg_ev.evaluate(results, {logReg_ev.metricName: 'weightedPrecision'}))\n",
    "print(logReg_ev.evaluate(results, {logReg_ev.metricName: 'weightedRecall'}))\n",
    "print(logReg_ev.evaluate(results, {logReg_ev.metricName: 'accuracy'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
